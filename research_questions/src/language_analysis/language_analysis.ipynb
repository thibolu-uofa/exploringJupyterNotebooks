{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language results for all files inside repositories data (for both SE and Non SE split)\n",
    "results obtained by running loc operation using the script 'language_all_repos.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>CodeBytes</th>\n",
       "      <th>Lines</th>\n",
       "      <th>Code</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Blank</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Count</th>\n",
       "      <th>WeightedComplexity</th>\n",
       "      <th>filename</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gitignore</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>.gitignore</td>\n",
       "      <td>3dmol/3Dmol.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAML</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>codecov.yml</td>\n",
       "      <td>3dmol/3Dmol.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>3346</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CODE_OF_CONDUCT.md</td>\n",
       "      <td>3dmol/3Dmol.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>1194</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTRIBUTING.md</td>\n",
       "      <td>3dmol/3Dmol.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>doc.md</td>\n",
       "      <td>3dmol/3Dmol.js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Bytes  CodeBytes  Lines  Code  Comment  Blank  Complexity  \\\n",
       "0  gitignore    369          0     31    28        1      2           0   \n",
       "1       YAML    378          0     18    16        2      0           0   \n",
       "2   Markdown   3346          0     76    57        0     19           0   \n",
       "3   Markdown   1194          0     27    17        0     10           0   \n",
       "4   Markdown   7918          0    178   117        0     61           0   \n",
       "\n",
       "   Count  WeightedComplexity            filename      repository  \n",
       "0      1                   0          .gitignore  3dmol/3Dmol.js  \n",
       "1      1                   0         codecov.yml  3dmol/3Dmol.js  \n",
       "2      1                   0  CODE_OF_CONDUCT.md  3dmol/3Dmol.js  \n",
       "3      1                   0     CONTRIBUTING.md  3dmol/3Dmol.js  \n",
       "4      1                   0              doc.md  3dmol/3Dmol.js  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_SE_df = pd.read_csv(Path(\"data_all_repos\", \"language_all_SE_repos.csv\"))\n",
    "repos_SE_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE purpose repositories\n",
    "analyzing the languages of all files belonging to SE purpose repositories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of analyzed files with scc for the SE split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155940"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_SE_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique languages of the SE split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_SE_df['Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the complete results in a txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"language_all_SE_repos.txt\", 'w', encoding='utf-8') as f:\n",
    "    for key, value in (repos_SE_df['Name'].value_counts()).items():\n",
    "        print(key, value, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of SE repositories that only contain Jupyter notebooks\n",
    "\n",
    "Obs: if a repository has README/markdown, license files and has only Jupyter \n",
    "notebooks as programming language, the repository is counted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check which repositories has only Jupyter notebooks as\n",
    "# programming language:\n",
    "\n",
    "def repos_only_jupyter_nbs(df):\n",
    "\n",
    "    allowed_formats = ['Plain Text', 'Markdown', 'CSV', 'YAML', 'JSON', 'Jupyter',\n",
    "                'XML', 'gitignore', 'License', 'TeX', 'LaTeX', 'ignore']\n",
    "    \n",
    "\n",
    "    # group by repository and check if all files in each repository have \n",
    "    # allowed extensions\n",
    "    repos_with_allowed_extensions = df.groupby('repository')['Name'].apply(lambda x: set(x).issubset(set(allowed_formats)))\n",
    "\n",
    "    count_repos_only_nbs = repos_with_allowed_extensions.sum()\n",
    "\n",
    "    repos_only_nbs = repos_with_allowed_extensions[repos_with_allowed_extensions].index.tolist()\n",
    "    print(f\"Number of repositories with only Jupyter notebooks \\nand/or\" \n",
    "          f\"documentation or license files: {count_repos_only_nbs}\")\n",
    "    \n",
    "    return repos_only_nbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of repos in the SE split with only Jupyter notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repositories with only Jupyter notebooks \n",
      "and/ordocumentation or license files: 15\n"
     ]
    }
   ],
   "source": [
    "repos_only_notebooks_SE = repos_only_jupyter_nbs(repos_SE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baiyuetribe/paper2gui',\n",
       " 'LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms',\n",
       " 'camenduru/stable-diffusion-webui-colab',\n",
       " 'deepmind/neural-processes',\n",
       " 'fastai/imagenette',\n",
       " 'gboeing/osmnx-examples',\n",
       " 'harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch',\n",
       " 'microsoft/Microsoft-365-Defender-Hunting-Queries',\n",
       " 'mxrch/penglab',\n",
       " 'priiyaanjaalii0611/ASL_to_English',\n",
       " 'rorysroes/SGX-Full-OrderBook-Tick-Data-Trading-Strategy',\n",
       " 'someshkar/colabcat',\n",
       " 'tjwei/GANotebooks',\n",
       " 'umutisik/Eigentechno',\n",
       " 'yaringal/multi-task-learning-example']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_only_notebooks_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"repos_only_notebooks_SE.txt\", 'w', encoding='utf-8') as f:\n",
    "    for repo_name in repos_only_notebooks_SE:\n",
    "        print(repo_name, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non SE purpose repositories\n",
    "analyzing the languages of all files belonging to Non SE purpose repositories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>CodeBytes</th>\n",
       "      <th>Lines</th>\n",
       "      <th>Code</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Blank</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Count</th>\n",
       "      <th>WeightedComplexity</th>\n",
       "      <th>filename</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gitignore</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>.gitignore</td>\n",
       "      <td>kmkolasinski/deep-learning-notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>1085</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>README.md</td>\n",
       "      <td>kmkolasinski/deep-learning-notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>README.md</td>\n",
       "      <td>kmkolasinski/deep-learning-notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jupyter</td>\n",
       "      <td>137316</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sinkhorn_knopp.ipynb</td>\n",
       "      <td>kmkolasinski/deep-learning-notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>1036</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sinkhorn_knopp.py</td>\n",
       "      <td>kmkolasinski/deep-learning-notes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name   Bytes  CodeBytes  Lines  Code  Comment  Blank  Complexity  \\\n",
       "0  gitignore     101          0      9     8        0      1           0   \n",
       "1   Markdown    1085          0     14     8        0      6           0   \n",
       "2   Markdown     717          0     16     9        0      7           0   \n",
       "3    Jupyter  137316          0    525   525        0      0           0   \n",
       "4     Python    1036          0     41    13       25      3           1   \n",
       "\n",
       "   Count  WeightedComplexity              filename  \\\n",
       "0      1                   0            .gitignore   \n",
       "1      1                   0             README.md   \n",
       "2      1                   0             README.md   \n",
       "3      1                   0  sinkhorn_knopp.ipynb   \n",
       "4      1                   0     sinkhorn_knopp.py   \n",
       "\n",
       "                         repository  \n",
       "0  kmkolasinski/deep-learning-notes  \n",
       "1  kmkolasinski/deep-learning-notes  \n",
       "2  kmkolasinski/deep-learning-notes  \n",
       "3  kmkolasinski/deep-learning-notes  \n",
       "4  kmkolasinski/deep-learning-notes  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_non_SE_df = pd.read_csv(Path(\"data_all_repos\", \"language_all_non_SE_repos.csv\"))\n",
    "repos_non_SE_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160487"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_non_SE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"language_all_non_SE_repos.txt\", 'w', encoding='utf-8') as f:\n",
    "    for key, value in (repos_non_SE_df['Name'].value_counts()).items():\n",
    "        print(key, value, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of distinct languages in the non SE split:\n",
    "Non se repos have more distinct languages than SE repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_non_SE_df['Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of repos in the non SE split with only Jupyter notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repositories with only Jupyter notebooks \n",
      "and/ordocumentation or license files: 116\n"
     ]
    }
   ],
   "source": [
    "repos_only_notebooks_non_SE =repos_only_jupyter_nbs(repos_non_SE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AileenNielsen/TimeSeriesAnalysisWithPython',\n",
       " 'Auquan/Tutorials',\n",
       " 'DLSchool/deep-learning-school',\n",
       " 'DanAnastasyev/DeepNLP-Course',\n",
       " 'Fafa-DL/Lhy_Machine_Learning',\n",
       " 'IBM/elasticsearch-spark-recommender',\n",
       " 'JWarmenhoven/DBDA-python',\n",
       " 'JWarmenhoven/ISLR-python',\n",
       " 'JifuZhao/DS-Take-Home',\n",
       " 'KlukvaMors/basic_stat',\n",
       " 'LYuhang/GNN_Review',\n",
       " 'LongOnly/Quantitative-Notebooks',\n",
       " 'MLEveryday/practicalAI-cn',\n",
       " 'MLNLP-World/DeepLearning-MuLi-Notes',\n",
       " 'MubertAI/Mubert-Text-to-Music',\n",
       " 'NielsRogge/Transformers-Tutorials',\n",
       " 'PacktPublishing/Hands-On-Reinforcement-Learning-with-Python',\n",
       " 'PacktPublishing/Pandas-Cookbook',\n",
       " 'PradyumnaKrishna/Colab-Hacks',\n",
       " 'SophonPlus/ChineseNlpCorpus',\n",
       " 'TommyZihao/zihaopython',\n",
       " 'ZeweiChu/PyTorch-Course',\n",
       " 'aarshayj/analytics_vidhya',\n",
       " 'abhimishra91/transformers-tutorials',\n",
       " 'adashofdata/nlp-in-python-tutorial',\n",
       " 'ageron/tf2_course',\n",
       " 'alirezadir/Machine-Learning-Interviews',\n",
       " 'aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3',\n",
       " 'ashishpatel26/Treasure-of-Transformers',\n",
       " 'aws-samples/aws-machine-learning-university-accelerated-cv',\n",
       " 'bentrevett/pytorch-sentiment-analysis',\n",
       " 'bentrevett/pytorch-seq2seq',\n",
       " 'caicloud/tensorflow-tutorial',\n",
       " 'caserec/Datasets-for-Recommender-Systems',\n",
       " 'chenzomi12/DeepLearningSystem',\n",
       " 'chiphuyen/just-pandas-things',\n",
       " 'coells/100days',\n",
       " 'curiousily/Deep-Learning-For-Hackers',\n",
       " 'cuttlefishh/python-for-data-analysis',\n",
       " 'czy36mengfei/tensorflow2_tutorials_chinese',\n",
       " 'dalmia/Deep-Learning-Book-Chapter-Summaries',\n",
       " 'datawhalechina/hands-on-data-analysis',\n",
       " 'datawhalechina/leedl-tutorial',\n",
       " 'deepmind/educational',\n",
       " 'devinpleuler/analytics-handbook',\n",
       " 'dformoso/sklearn-classification',\n",
       " 'dvschultz/ml-art-colabs',\n",
       " 'eleanorlutz/asteroids_atlas_of_space',\n",
       " 'empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks',\n",
       " 'enggen/Deep-Learning-Coursera',\n",
       " 'erhwenkuo/deep-learning-with-keras-notebooks',\n",
       " 'fastai/numerical-linear-algebra',\n",
       " 'fchollet/deep-learning-with-python-notebooks',\n",
       " 'fengdu78/lihang-code',\n",
       " 'firmai/awesome-google-colab',\n",
       " 'firmai/business-machine-learning',\n",
       " 'firmai/industry-machine-learning',\n",
       " 'firmai/machine-learning-asset-management',\n",
       " 'fly51fly/Practical_Python_Programming',\n",
       " 'ga642381/ML2021-Spring',\n",
       " 'girls-in-ai/Girls-In-AI',\n",
       " 'guipsamora/pandas_exercises',\n",
       " 'hadrienj/deepLearningBook-Notes',\n",
       " 'hardikkamboj/An-Introduction-to-Statistical-Learning',\n",
       " 'hemansnation/Data-Science-ML-Full-Stack',\n",
       " 'higgsfield/Capsule-Network-Tutorial',\n",
       " 'hktxt/Learn-Statistical-Learning-Method',\n",
       " 'https-deeplearning-ai/tensorflow-1-public',\n",
       " 'huggingface/deep-rl-class',\n",
       " 'iamtrask/Grokking-Deep-Learning',\n",
       " 'ine-rmotr-curriculum/FreeCodeCamp-Pandas-Real-Life-Example',\n",
       " 'ipython-books/cookbook-2nd-code',\n",
       " 'jadianes/spark-py-notebooks',\n",
       " 'jayinai/data-science-question-answer',\n",
       " 'jayinai/ml-interview',\n",
       " 'jmportilla/Complete-Python-Bootcamp',\n",
       " 'jmportilla/Python-for-Algorithms--Data-Structures--and-Interviews',\n",
       " 'jmtomczak/intro_dgm',\n",
       " 'jrfiedler/causal_inference_python_code',\n",
       " 'justmarkham/scikit-learn-tips',\n",
       " 'km1994/NLP-Interview-Notes',\n",
       " 'krishnaik06/Interview-Prepartion-Data-Science',\n",
       " 'krishnaik06/Machine-Learning-in-90-days',\n",
       " 'kuleshov/teaching-material',\n",
       " 'lexfridman/mit-deep-learning',\n",
       " 'lijin-THU/notes-machine-learning',\n",
       " 'lixin4ever/Conference-Acceptance-Rate',\n",
       " 'lyhue1991/eat_pytorch_in_20_days',\n",
       " 'mahmoud/awesome-python-applications',\n",
       " 'mitmath/julia-mit',\n",
       " 'mml-book/mml-book.github.io',\n",
       " 'musikalkemist/AudioSignalProcessingForML',\n",
       " 'naganandy/graph-based-deep-learning-literature',\n",
       " 'ndb796/Deep-Learning-Paper-Review-and-Practice',\n",
       " 'nickmccullum/algorithmic-trading-python',\n",
       " 'nicknochnack/TFODCourse',\n",
       " 'ossamamehmood/Hacktoberfest2022',\n",
       " 'patrick-llgc/Learning-Deep-Learning',\n",
       " 'rasbt/matplotlib-gallery',\n",
       " 'rguthrie3/DeepLearningForNLPInPytorch',\n",
       " 'roboticcam/machine-learning-notes',\n",
       " 'sudharsan13296/Hands-On-Meta-Learning-With-Python',\n",
       " 'sudharsan13296/Hands-On-Reinforcement-Learning-With-Python',\n",
       " 'tdpetrou/Machine-Learning-Books-With-Python',\n",
       " 'tugstugi/dl-colab-notebooks',\n",
       " 'veb-101/Data-Science-Projects',\n",
       " 'xavier-zy/Awesome-pytorch-list-CNVersion',\n",
       " 'xinychen/latex-cookbook',\n",
       " 'ypwhs/dogs_vs_cats',\n",
       " 'yuanxiaosc/Machine-Learning-Book',\n",
       " 'zergtant/pytorch-handbook',\n",
       " 'zlotus/notes-LSJU-machine-learning',\n",
       " 'zlotus/notes-linear-algebra',\n",
       " 'zotroneneis/machine_learning_basics',\n",
       " 'zslucky/awesome-AI-books',\n",
       " 'zygmuntz/goodbooks-10k']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_only_notebooks_non_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"repos_only_notebooks_non_SE.txt\", 'w', encoding='utf-8') as f:\n",
    "    for repo_name in repos_only_notebooks_non_SE:\n",
    "        print(repo_name, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
